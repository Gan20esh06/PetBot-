<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1.0, user-scalable=no"
    />
    <title>AI Avatar Assistant</title>

    <!-- TensorFlow.js and YOLO for Object Detection -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.11.0"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd@2.2.3"></script>
    <!-- YOLOv5 implementation -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl@4.11.0"></script>

    <style>
      /* ===== GLOBAL STYLES ===== */
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }

      body {
        background: linear-gradient(
          135deg,
          #8b5cf6 0%,
          #a78bfa 25%,
          #c4b5fd 50%,
          #a78bfa 75%,
          #8b5cf6 100%
        );
        font-family: "Comic Sans MS", "Segoe UI", Tahoma, Geneva, Verdana,
          sans-serif;
        display: flex;
        justify-content: center;
        align-items: center;
        min-height: 100vh;
        overflow: hidden;
      }

      /* ===== CAMERA VIDEO (Hidden, used for object detection) ===== */
      #cameraVideo {
        position: fixed;
        top: 0;
        left: 0;
        width: 1px;
        height: 1px;
        opacity: 0;
        pointer-events: none;
      }

      .avatar-container {
        position: relative;
        display: flex;
        flex-direction: column;
        align-items: center;
      }

      /* ===== AVATAR FACE - CIRCULAR WITH 3D EFFECT ===== */
      .avatar-face {
        width: 280px;
        height: 280px;
        background: radial-gradient(
          circle at 40% 30%,
          #a78bfa,
          #8b5cf6,
          #7c3aed
        );
        border-radius: 50%;
        position: relative;
        box-shadow: 0 25px 50px rgba(139, 92, 246, 0.6),
          inset 0 8px 16px rgba(255, 255, 255, 0.2),
          inset 0 -8px 16px rgba(124, 58, 237, 0.3),
          0 0 60px rgba(167, 139, 250, 0.4);
        display: flex;
        align-items: center;
        justify-content: center;
        border: 4px solid rgba(255, 255, 255, 0.3);
      }

      .face-content {
        position: relative;
        width: 220px;
        height: 220px;
      }

      /* Wake word listening - subtle pulse */
      .avatar-face.wake-listening {
        animation: wakePulse 3s ease-in-out infinite;
      }

      @keyframes wakePulse {
        0%,
        100% {
          box-shadow: 0 20px 60px rgba(0, 0, 0, 0.4),
            inset 0 -5px 15px rgba(0, 0, 0, 0.1);
        }
        50% {
          box-shadow: 0 20px 60px rgba(0, 0, 0, 0.4),
            0 0 30px rgba(59, 130, 246, 0.3),
            inset 0 -5px 15px rgba(0, 0, 0, 0.1);
        }
      }

      .avatar-face.listening {
        transform: scale(1.05);
        box-shadow: 0 20px 80px rgba(59, 130, 246, 0.6),
          inset 0 -5px 15px rgba(0, 0, 0, 0.1);
      }

      .avatar-face.speaking {
        animation: speakPulse 0.5s ease-in-out infinite;
      }

      @keyframes speakPulse {
        0%,
        100% {
          transform: scale(1);
        }
        50% {
          transform: scale(1.02);
        }
      }

      /* Enhanced Eyes with 3D gradient */
      .eye {
        width: 55px;
        height: 55px;
        background: radial-gradient(
          circle at 30% 30%,
          #ffffff,
          #f8fafc,
          #e2e8f0
        );
        border-radius: 50%;
        position: absolute;
        top: 55px;
        box-shadow: inset 0 2px 6px rgba(0, 0, 0, 0.15),
          0 4px 12px rgba(0, 0, 0, 0.2), 0 0 20px rgba(255, 255, 255, 0.5);
        animation: naturalBlink 5s infinite;
        border: 3px solid rgba(255, 255, 255, 0.8);
      }

      .eye.left {
        left: 45px;
      }
      .eye.right {
        right: 45px;
      }

      .pupil {
        width: 26px;
        height: 26px;
        background: radial-gradient(circle at 35% 35%, #1e293b, #000000);
        border-radius: 50%;
        position: absolute;
        top: 50%;
        left: 50%;
        transform: translate(-50%, -50%);
        transition: all 0.2s ease-out;
        box-shadow: 0 2px 6px rgba(0, 0, 0, 0.4);
      }

      .eye-shine {
        width: 8px;
        height: 8px;
        background: #ffffff;
        border-radius: 50%;
        position: absolute;
        top: 30%;
        left: 35%;
        opacity: 0.8;
      }

      /* Listening state - glowing blue eyes with pulse */
      .avatar-face.listening .eye {
        background: radial-gradient(circle, #f472b6, #ec4899, #db2777);
        width: 70px;
        height: 70px;
        box-shadow: 0 0 40px rgba(236, 72, 153, 1),
          0 0 60px rgba(244, 114, 182, 0.8), inset 0 2px 8px rgba(0, 0, 0, 0.2);
        animation: eyeGlowPulse 1s ease-in-out infinite;
      }

      @keyframes eyeGlowPulse {
        0%,
        100% {
          box-shadow: 0 0 40px rgba(236, 72, 153, 1),
            0 0 60px rgba(244, 114, 182, 0.8),
            inset 0 2px 8px rgba(0, 0, 0, 0.2);
          transform: scale(1);
        }
        50% {
          box-shadow: 0 0 60px rgba(236, 72, 153, 1),
            0 0 90px rgba(244, 114, 182, 1), inset 0 2px 8px rgba(0, 0, 0, 0.2);
          transform: scale(1.1);
        }
      }

      /* Processing state - thinking eyes */
      .avatar-face.processing .eye {
        background: radial-gradient(circle, #c4b5fd, #a78bfa, #8b5cf6);
        animation: eyeThink 2s ease-in-out infinite;
      }

      @keyframes eyeThink {
        0%,
        100% {
          box-shadow: 0 0 20px rgba(139, 92, 246, 0.6);
        }
        50% {
          box-shadow: 0 0 40px rgba(139, 92, 246, 1);
        }
      }

      /* Speaking state - expressive eyes */
      .avatar-face.speaking .eye {
        background: radial-gradient(circle, #86efac, #4ade80, #22c55e);
      }

      .avatar-face.speaking .eye::before {
        animation: pupilMove 0.5s ease-in-out infinite;
      }

      @keyframes pupilMove {
        0%,
        100% {
          transform: translate(-50%, -50%);
        }
        25% {
          transform: translate(-45%, -50%);
        }
        75% {
          transform: translate(-55%, -50%);
        }
      }

      /* Natural blinking animation */
      .eye.blinking {
        animation: blink 4s ease-in-out infinite;
      }

      @keyframes blink {
        0%,
        96%,
        100% {
          height: 60px;
          border-radius: 50%;
        }
        98% {
          height: 8px;
          border-radius: 50% 50% 50% 50% / 30% 30% 70% 70%;
        }
      }

      /* Enhanced Mouth with gradient background */
      .mouth {
        width: 80px;
        height: 40px;
        border: 4px solid rgba(0, 0, 0, 0.6);
        border-top: none;
        border-radius: 0 0 80px 80px;
        position: absolute;
        bottom: 45px;
        left: 50%;
        transform: translateX(-50%);
        transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1);
        background: linear-gradient(
          to bottom,
          rgba(139, 92, 246, 0.2),
          rgba(124, 58, 237, 0.3)
        );
      }

      .mouth.speaking {
        animation: advancedSpeak 0.4s ease-in-out infinite alternate;
        border-color: #e74c3c;
      }

      .mouth.happy {
        border-radius: 80px 80px 0 0;
        border-top: 4px solid rgba(0, 0, 0, 0.6);
        border-bottom: none;
        background: linear-gradient(
          to top,
          rgba(244, 114, 182, 0.3),
          rgba(236, 72, 153, 0.2)
        );
        transform: translateX(-50%) translateY(-8px);
      }

      .mouth.thinking {
        width: 70px;
        height: 35px;
        border-radius: 35px;
        border: 5px solid #f39c12;
        background: rgba(243, 156, 18, 0.1);
      }

      /* Advanced speaking animation */
      @keyframes advancedSpeak {
        0% {
          width: 90px;
          height: 45px;
          border-radius: 0 0 90px 90px;
          transform: translateX(-50%) scale(1);
        }
        50% {
          width: 110px;
          height: 60px;
          border-radius: 0 0 110px 110px;
          transform: translateX(-50%) scale(1.05);
        }
        100% {
          width: 95px;
          height: 50px;
          border-radius: 0 0 95px 95px;
          transform: translateX(-50%) scale(1.02);
        }
      }

      /* Natural blinking animation */
      @keyframes naturalBlink {
        0%,
        90%,
        100% {
          height: 50px;
          transform: scaleY(1);
        }
        95% {
          height: 8px;
          transform: scaleY(0.1);
        }
      }

      /* Status ring around avatar */
      .status-ring {
        position: absolute;
        width: 320px;
        height: 320px;
        border: 4px solid transparent;
        border-radius: 50%;
        top: 50%;
        left: 50%;
        transform: translate(-50%, -50%);
        transition: all 0.5s ease;
        z-index: -1;
      }

      .status-ring.listening {
        border-color: #f472b6;
        animation: listeningPulse 1.2s ease-in-out infinite;
      }

      .status-ring.thinking {
        border-color: #f39c12;
        animation: thinkingRotate 2s linear infinite;
      }

      .status-ring.speaking {
        border-color: #27ae60;
        animation: speakingGlow 0.8s ease-in-out infinite alternate;
      }

      @keyframes listeningPulse {
        0% {
          transform: translate(-50%, -50%) scale(1);
          opacity: 0.8;
        }
        50% {
          transform: translate(-50%, -50%) scale(1.08);
          opacity: 1;
        }
        100% {
          transform: translate(-50%, -50%) scale(1);
          opacity: 0.8;
        }
      }

      @keyframes thinkingRotate {
        from {
          transform: translate(-50%, -50%) rotate(0deg);
        }
        to {
          transform: translate(-50%, -50%) rotate(360deg);
        }
      }

      @keyframes speakingGlow {
        from {
          box-shadow: 0 0 20px rgba(39, 174, 96, 0.4);
          transform: translate(-50%, -50%) scale(1);
        }
        to {
          box-shadow: 0 0 40px rgba(39, 174, 96, 0.8);
          transform: translate(-50%, -50%) scale(1.05);
        }
      }

      /* Wake word indicator */
      .wake-indicator {
        margin-top: 30px;
        color: rgba(255, 255, 255, 1);
        font-size: 17px;
        text-align: center;
        font-weight: 500;
        text-shadow: 0 3px 8px rgba(0, 0, 0, 0.5),
          0 0 20px rgba(255, 255, 255, 0.3);
      }

      .wake-word {
        color: #f472b6;
        font-weight: bold;
        text-shadow: 0 0 12px rgba(244, 114, 182, 0.8),
          0 0 20px rgba(236, 72, 153, 0.5);
      }

      .status-text {
        margin-top: 15px;
        color: rgba(255, 255, 255, 0.7);
        font-size: 14px;
        font-style: italic;
      }

      /* ===== WAKE WORD INDICATOR ===== */
      .wake-word-indicator {
        position: fixed;
        top: 20px;
        left: 50%;
        transform: translateX(-50%);
        padding: 10px 20px;
        background: rgba(34, 197, 94, 0.9);
        color: white;
        border-radius: 20px;
        font-size: 14px;
        font-weight: bold;
        box-shadow: 0 4px 15px rgba(34, 197, 94, 0.4);
        z-index: 200;
        opacity: 0;
        transition: opacity 0.3s ease;
      }

      .wake-word-indicator.active {
        opacity: 1;
        animation: wakeWordPulse 1s ease-in-out infinite;
      }

      @keyframes wakeWordPulse {
        0%,
        100% {
          transform: translateX(-50%) scale(1);
        }
        50% {
          transform: translateX(-50%) scale(1.05);
        }
      }

      /* ===== CHAT BUBBLE ===== */
      .chat-bubble {
        position: fixed;
        bottom: 30px;
        left: 50%;
        transform: translateX(-50%) translateY(20px);
        max-width: 80%;
        padding: 15px 20px;
        background: rgba(255, 255, 255, 0.95);
        color: #1f2937;
        border-radius: 20px;
        font-size: 16px;
        box-shadow: 0 8px 20px rgba(0, 0, 0, 0.3);
        opacity: 0;
        transition: all 0.3s ease;
        z-index: 150;
        text-align: center;
        backdrop-filter: blur(10px);
      }

      .chat-bubble.visible {
        opacity: 1;
        transform: translateX(-50%) translateY(0);
      }

      .chat-bubble.bot {
        background: rgba(59, 130, 246, 0.95);
        color: white;
      }

      /* ===== SETTINGS PANEL ===== */
      /* Settings icon button */
      .settings-icon {
        position: fixed;
        top: 20px;
        right: 20px;
        width: 50px;
        height: 50px;
        background: rgba(139, 92, 246, 0.9);
        border-radius: 50%;
        display: flex;
        align-items: center;
        justify-content: center;
        cursor: pointer;
        font-size: 24px;
        z-index: 101;
        backdrop-filter: blur(10px);
        border: 3px solid rgba(255, 255, 255, 0.4);
        transition: all 0.3s ease;
        box-shadow: 0 4px 15px rgba(139, 92, 246, 0.5);
      }

      .settings-icon:hover {
        background: rgba(236, 72, 153, 0.9);
        border-color: #f472b6;
        transform: rotate(90deg);
        box-shadow: 0 6px 20px rgba(236, 72, 153, 0.6);
      }

      /* Settings panel - hidden by default */
      .settings-panel {
        position: fixed;
        top: 20px;
        right: 20px;
        background: rgba(139, 92, 246, 0.95);
        padding: 20px;
        border-radius: 15px;
        color: white;
        font-size: 12px;
        max-width: 300px;
        z-index: 100;
        backdrop-filter: blur(10px);
        display: none;
        border: 3px solid rgba(255, 255, 255, 0.3);
        box-shadow: 0 8px 32px rgba(139, 92, 246, 0.6);
      }

      .settings-panel.open {
        display: block;
        animation: slideIn 0.3s ease;
      }

      @keyframes slideIn {
        from {
          opacity: 0;
          transform: translateX(20px);
        }
        to {
          opacity: 1;
          transform: translateX(0);
        }
      }

      .settings-panel h3 {
        margin-bottom: 10px;
        font-size: 14px;
        display: flex;
        justify-content: space-between;
        align-items: center;
      }

      .close-settings {
        cursor: pointer;
        font-size: 20px;
        color: #ef4444;
        padding: 0 5px;
      }

      .close-settings:hover {
        color: #dc2626;
      }

      .settings-panel input {
        width: 100%;
        padding: 8px;
        margin: 5px 0;
        border-radius: 5px;
        border: none;
        background: rgba(255, 255, 255, 0.1);
        color: white;
      }

      .settings-panel button {
        width: 100%;
        padding: 10px;
        margin: 5px 0;
        border-radius: 8px;
        border: none;
        background: #ec4899;
        color: white;
        cursor: pointer;
        font-weight: bold;
        box-shadow: 0 3px 10px rgba(236, 72, 153, 0.4);
      }

      .settings-panel button:hover {
        background: #db2777;
        box-shadow: 0 4px 15px rgba(219, 39, 119, 0.6);
      }

      .settings-panel .toggle {
        display: flex;
        align-items: center;
        justify-content: space-between;
        margin: 10px 0;
      }

      /* ===== OBJECT DETECTION OVERLAY ===== */
      .detection-overlay {
        position: fixed;
        top: 80px;
        left: 20px;
        background: rgba(0, 0, 0, 0.8);
        padding: 15px;
        border-radius: 10px;
        color: white;
        font-size: 12px;
        max-width: 250px;
        z-index: 100;
        backdrop-filter: blur(10px);
      }

      .detection-overlay h4 {
        margin-bottom: 8px;
        color: #3b82f6;
      }

      .detection-item {
        padding: 5px 0;
        border-bottom: 1px solid rgba(255, 255, 255, 0.1);
      }

      /* ===== LOG CONSOLE ===== */
      .log-console {
        position: fixed;
        bottom: 0;
        left: 0;
        right: 0;
        height: 200px;
        background: rgba(0, 0, 0, 0.95);
        color: #00ff00;
        font-family: "Courier New", monospace;
        font-size: 11px;
        padding: 10px;
        overflow-y: auto;
        z-index: 50;
        transform: translateY(100%);
        transition: transform 0.3s ease;
      }

      .log-console.visible {
        transform: translateY(0);
      }

      .log-entry {
        padding: 2px 0;
        opacity: 0.8;
      }

      /* ===== TOGGLE LOG BUTTON ===== */
      .toggle-log-btn {
        position: fixed;
        bottom: 10px;
        right: 10px;
        padding: 8px 15px;
        background: rgba(0, 0, 0, 0.7);
        color: white;
        border: none;
        border-radius: 5px;
        cursor: pointer;
        font-size: 12px;
        z-index: 100;
      }

      /* ===== RESPONSIVE ===== */
      @media (max-width: 600px) {
        .avatar-face {
          width: min(280px, 70vw);
          height: min(280px, 70vw);
        }

        .eyes {
          gap: 50px;
          margin-bottom: 40px;
        }

        .eye {
          width: 50px;
          height: 50px;
        }

        .mouth {
          width: 100px;
          height: 50px;
        }

        .status {
          font-size: 16px;
          padding: 10px 20px;
        }

        .settings-panel {
          top: 10px;
          right: 10px;
          max-width: calc(100% - 20px);
        }

        .settings-icon {
          top: 10px;
          right: 10px;
          width: 45px;
          height: 45px;
          font-size: 20px;
        }
      }

      /* Landscape orientation adjustments */
      @media (orientation: landscape) {
        .avatar-face {
          width: min(250px, 40vh);
          height: min(250px, 40vh);
        }

        .face-content {
          width: 180px;
          height: 180px;
        }

        .eye {
          width: 45px;
          height: 45px;
        }

        .eye.left {
          left: 35px;
        }

        .eye.right {
          right: 35px;
        }

        .pupil {
          width: 18px;
          height: 18px;
        }

        .mouth {
          width: 90px;
          height: 45px;
          bottom: 30px;
        }

        .wake-indicator {
          font-size: 18px;
          margin-top: 15px;
        }

        .status-text {
          font-size: 14px;
          margin-top: 8px;
        }

        .settings-icon {
          top: 15px;
          right: 15px;
        }

        .settings-panel {
          top: 15px;
          right: 15px;
          max-width: 280px;
          max-height: calc(100vh - 40px);
          overflow-y: auto;
        }
      }
    </style>
  </head>
  <body>
    <div class="avatar-container">
      <div class="status-ring" id="statusRing"></div>
      <div class="avatar-face">
        <div class="face-content">
          <div class="eye left">
            <div class="pupil" id="leftPupil">
              <div class="eye-shine"></div>
            </div>
          </div>
          <div class="eye right">
            <div class="pupil" id="rightPupil">
              <div class="eye-shine"></div>
            </div>
          </div>
          <div class="mouth" id="mouth"></div>
        </div>
      </div>
      <div class="wake-indicator">
        Say "<span class="wake-word">Hey Robot</span>" to start
      </div>
      <div class="status-text" id="statusText">Listening for wake word...</div>
      <div class="status-text" id="lastTranscriptText"></div>
    </div>

    <!-- Chat Bubble -->
    <div class="chat-bubble" id="chatBubble"></div>

    <!-- Settings Icon (Always Visible) -->
    <div class="settings-icon" id="settingsIcon">‚öôÔ∏è</div>

    <!-- Settings Panel (Hidden by default) -->
    <div class="settings-panel" id="settingsPanel">
      <h3>
        <span>‚öôÔ∏è Settings</span>
        <span class="close-settings" id="closeSettings">‚úñ</span>
      </h3>

      <label>Gemini AI API Key:</label>
      <input type="password" id="openaiApiKey" placeholder="AIza..." />

      <label>Wake Word:</label>
      <input
        type="text"
        id="wakeWord"
        value="hey robot"
        placeholder="hey robot"
      />

      <label>Ground Station URL:</label>
      <input
        type="text"
        id="groundStationUrl"
        placeholder="http://192.168.1.100:5000/data"
      />

      <button id="connectEsp32Btn">üì∂ Connect ESP32</button>

      <div class="toggle">
        <span>Object Detection:</span>
        <input type="checkbox" id="objectDetectionToggle" />
      </div>

      <div class="toggle">
        <span>Ground Station:</span>
        <input type="checkbox" id="groundStationToggle" />
      </div>

      <button id="saveSettingsBtn">üíæ Save Settings</button>
    </div>

    <!-- Object Detection Overlay -->
    <div class="detection-overlay" id="detectionOverlay" style="display: none">
      <h4>üì∑ Detected Objects</h4>
      <div id="detectionList"></div>
    </div>

    <!-- Hidden Camera Video for Object Detection -->
    <video id="cameraVideo" autoplay playsinline></video>

    <!-- Log Console -->
    <div class="log-console" id="logConsole"></div>
    <button class="toggle-log-btn" id="toggleLogBtn">Show Log</button>

    <script>
      // ===== CONFIGURATION =====
      const CONFIG = {
        openaiApiKey:
          localStorage.getItem("openaiApiKey") ||
          "AIzaSyCjZ6IyZjP0MVRbsPNS9T6Tr6T3H4vAqCA",
        wakeWord: localStorage.getItem("wakeWord") || "hey robot",
        groundStationUrl: localStorage.getItem("groundStationUrl") || "",
        objectDetectionEnabled:
          localStorage.getItem("objectDetectionEnabled") === "true",
        groundStationEnabled:
          localStorage.getItem("groundStationEnabled") === "true",
        // Object tracking settings
        lockedObject: null, // {class: 'person', bbox: [...]}
        trackingEnabled: false,
        websocketUrl:
          localStorage.getItem("websocketUrl") || "ws://localhost:8080",
      };

      // ===== STATE MANAGEMENT =====
      let isListening = false;
      let isProcessing = false;
      let isSpeaking = false;
      let isInCommandMode = false; // Track if in continuous command mode

      // Rate limiting for Gemini API (15 requests/minute free tier)
      let lastGeminiCallTime = 0;
      const GEMINI_MIN_DELAY = 4000; // 4 seconds between calls (15 per minute = 1 every 4 seconds)

      // Object tracking state
      let yoloModel = null;
      let detectionInterval = null;
      let lastTrackingCommand = 0;
      const TRACKING_COMMAND_DELAY = 500; // Send movement commands every 500ms
      let websocket = null;

      let wakeWordRecognition = null;
      let commandRecognition = null;
      let synthesis = window.speechSynthesis;

      // Recognition lifecycle guards
      let wakeRestartTimeoutId = null; // prevents rapid restart loops
      let activationLock = false; // debounces multiple wake triggers
      let micWarmStream = null; // optional: keep mic engaged to avoid flicker
      let listeningAckTimeoutId = null; // delayed ack to avoid blocking user speech
      let commandFallbackTimeoutId = null; // fallback to Web Speech if AAI stays silent
      let lastTranscriptTimestamp = 0; // updated on any transcript

      // Command processing guards
      let lastProcessedCommand = ""; // Track last command to prevent duplicates
      let lastCommandTime = 0; // Timestamp of last command
      let commandProcessingLock = false; // Prevent processing multiple commands simultaneously

      // Bluetooth
      let bluetoothDevice = null;
      let bluetoothCharacteristic = null;
      let isBluetoothConnected = false;
      const UART_SERVICE_UUID = "6e400001-b5a3-f393-e0a9-e50e24dcca9e";
      const UART_TX_CHARACTERISTIC_UUID =
        "6e400002-b5a3-f393-e0a9-e50e24dcca9e";
      const UART_RX_CHARACTERISTIC_UUID =
        "6e400003-b5a3-f393-e0a9-e50e24dcca9e";

      // Object Detection
      let cameraStream = null;
      let detectedObjects = [];
      let cocoSsdModel = null; // Legacy COCO-SSD model (keeping for fallback)

      // ===== DOM ELEMENTS =====
      const mouth = document.getElementById("mouth");
      const leftPupil = document.getElementById("leftPupil");
      const rightPupil = document.getElementById("rightPupil");
      const statusRing = document.getElementById("statusRing");
      const statusText = document.getElementById("statusText");
      const lastTranscriptText = document.getElementById("lastTranscriptText");
      const logConsole = document.getElementById("logConsole");
      const toggleLogBtn = document.getElementById("toggleLogBtn");
      const openaiApiKeyInput = document.getElementById("openaiApiKey");
      const wakeWordInput = document.getElementById("wakeWord");
      const groundStationUrlInput = document.getElementById("groundStationUrl");
      const objectDetectionToggle = document.getElementById(
        "objectDetectionToggle"
      );
      const groundStationToggle = document.getElementById(
        "groundStationToggle"
      );
      const saveSettingsBtn = document.getElementById("saveSettingsBtn");
      const connectEsp32Btn = document.getElementById("connectEsp32Btn");
      const detectionOverlay = document.getElementById("detectionOverlay");
      const detectionList = document.getElementById("detectionList");
      const cameraVideo = document.getElementById("cameraVideo");
      const settingsIcon = document.getElementById("settingsIcon");
      const settingsPanel = document.getElementById("settingsPanel");
      const closeSettings = document.getElementById("closeSettings");

      // ===== AUDIO UNLOCK FOR MOBILE/ANDROID =====
      let audioUnlocked = false;
      let voicesLoaded = false;

      function unlockAudio() {
        if (audioUnlocked) return;

        try {
          // Resume audio context if exists
          if (window.AudioContext || window.webkitAudioContext) {
            const AudioContext =
              window.AudioContext || window.webkitAudioContext;
            const ctx = new AudioContext();
            if (ctx.state === "suspended") {
              ctx.resume().then(() => {
                logMsg("üîä AudioContext resumed");
              });
            }
            ctx.close();
          }

          // Prime speech synthesis by speaking silence - CRITICAL for Android
          if (window.speechSynthesis) {
            // Cancel any pending speech
            window.speechSynthesis.cancel();

            // Wait for voices to load
            if (speechSynthesis.getVoices().length === 0) {
              logMsg("‚è≥ Waiting for voices to load...");
              speechSynthesis.addEventListener(
                "voiceschanged",
                function () {
                  voicesLoaded = true;
                  logMsg(
                    "‚úÖ Voices loaded: " + speechSynthesis.getVoices().length
                  );
                },
                { once: true }
              );
            } else {
              voicesLoaded = true;
              logMsg(
                "‚úÖ Voices already available: " +
                  speechSynthesis.getVoices().length
              );
            }

            // Speak silent utterance to prime the engine
            const utterance = new SpeechSynthesisUtterance(" ");
            utterance.volume = 0.01; // Very quiet but not 0
            utterance.rate = 1.0;
            utterance.pitch = 1.0;
            window.speechSynthesis.speak(utterance);
          }

          audioUnlocked = true;
          logMsg("üîä Audio unlocked for mobile");
        } catch (e) {
          logMsg("‚ö†Ô∏è Audio unlock failed: " + e.message);
        }
      }

      // ===== INITIALIZATION =====
      async function init() {
        // First check that all DOM elements exist
        if (!toggleLogBtn || !settingsIcon || !closeSettings) {
          console.error("Critical DOM elements not found!");
          return;
        }

        logMsg("ü§ñ AI Avatar Assistant initialized");

        // Unlock audio on mobile/Android - CRITICAL for WebView
        document.addEventListener("click", unlockAudio, { once: true });
        document.addEventListener("touchstart", unlockAudio, { once: true });

        // Try to unlock audio immediately
        unlockAudio();

        // Load saved settings
        loadSettings();

        // Check browser support for Web Speech
        if (
          !("webkitSpeechRecognition" in window) &&
          !("SpeechRecognition" in window)
        ) {
          logMsg("‚ùå Web Speech API not supported");
          statusText.textContent = "Speech recognition not available";
          // Keep UI, object detection, and other features functional
        } else {
          logMsg("üéß Using Web Speech API for STT");
          // Initialize Web Speech recognitions
          initWakeWordRecognition();
          initCommandRecognition();
        }

        // Setup event listeners
        toggleLogBtn.addEventListener("click", toggleLog);
        saveSettingsBtn.addEventListener("click", saveSettings);
        connectEsp32Btn.addEventListener("click", connectBluetooth);
        objectDetectionToggle.addEventListener("change", toggleObjectDetection);
        groundStationToggle.addEventListener("change", toggleGroundStation);

        // Settings panel toggle
        settingsIcon.addEventListener("click", () => {
          settingsPanel.classList.add("open");
          settingsIcon.style.display = "none";
        });

        closeSettings.addEventListener("click", () => {
          settingsPanel.classList.remove("open");
          settingsIcon.style.display = "flex";
        });

        // Start natural eye movement
        animateEyes();
        setInterval(animateEyes, 3000);

        // Optional: warm up microphone to reduce connect/disconnect flicker (best on localhost/https)
        try {
          // Comment out if you don't want a persistent mic indicator
          navigator.mediaDevices
            ?.getUserMedia?.({ audio: true })
            .then((s) => {
              micWarmStream = s;
              logMsg("üé§ Mic warm-up stream active");
            })
            .catch(() => {});
        } catch (_) {}

        // Start wake word listening
        startWakeWordListening();

        // Connect to WebSocket server for remote control
        connectWebSocket();

        logMsg("‚úÖ System ready - listening for wake word");
      }

      // ===== WEBSOCKET CONNECTION FOR REMOTE CONTROL =====
      function connectWebSocket() {
        try {
          websocket = new WebSocket(CONFIG.websocketUrl);

          websocket.onopen = () => {
            logMsg("üåê Connected to remote control server");
          };

          websocket.onmessage = (event) => {
            try {
              const data = JSON.parse(event.data);

              if (data.type === "lock") {
                // Remote phone locked an object
                CONFIG.lockedObject = data.object;
                CONFIG.trackingEnabled = true;
                logMsg(`üîí Remote lock: ${data.object.class}`);
                updateDetectionDisplay();
              } else if (data.type === "unlock") {
                // Remote phone unlocked object
                CONFIG.lockedObject = null;
                CONFIG.trackingEnabled = false;
                sendCommand("S");
                logMsg(`üîì Remote unlock`);
                updateDetectionDisplay();
              }
            } catch (error) {
              console.error("WebSocket message error:", error);
            }
          };

          websocket.onerror = (error) => {
            logMsg("‚ö†Ô∏è WebSocket error - remote control unavailable");
          };

          websocket.onclose = () => {
            logMsg("üåê Disconnected from remote control server");
            // Attempt reconnection after 5 seconds
            setTimeout(connectWebSocket, 5000);
          };
        } catch (error) {
          logMsg("‚ö†Ô∏è WebSocket not available - remote control disabled");
        }
      }

      // ===== SETTINGS MANAGEMENT =====
      function loadSettings() {
        openaiApiKeyInput.value = CONFIG.openaiApiKey;
        wakeWordInput.value = CONFIG.wakeWord;
        groundStationUrlInput.value = CONFIG.groundStationUrl;
        objectDetectionToggle.checked = CONFIG.objectDetectionEnabled;
        groundStationToggle.checked = CONFIG.groundStationEnabled;

        if (CONFIG.objectDetectionEnabled) {
          startObjectDetection();
        }
      }

      function saveSettings() {
        CONFIG.openaiApiKey = openaiApiKeyInput.value;
        CONFIG.wakeWord = wakeWordInput.value.toLowerCase();
        CONFIG.groundStationUrl = groundStationUrlInput.value;
        CONFIG.objectDetectionEnabled = objectDetectionToggle.checked;
        CONFIG.groundStationEnabled = groundStationToggle.checked;

        localStorage.setItem("openaiApiKey", CONFIG.openaiApiKey);
        localStorage.setItem("wakeWord", CONFIG.wakeWord);
        localStorage.setItem("groundStationUrl", CONFIG.groundStationUrl);
        localStorage.setItem(
          "objectDetectionEnabled",
          CONFIG.objectDetectionEnabled
        );
        localStorage.setItem(
          "groundStationEnabled",
          CONFIG.groundStationEnabled
        );

        logMsg("üíæ Settings saved");
        showChatBubble("Settings saved successfully!", "bot");
      }

      // ===== WAKE WORD RECOGNITION =====
      function initWakeWordRecognition() {
        const SpeechRecognition =
          window.SpeechRecognition || window.webkitSpeechRecognition;

        if (!SpeechRecognition) {
          logMsg("‚ùå Speech Recognition not available");
          return;
        }

        wakeWordRecognition = new SpeechRecognition();
        wakeWordRecognition.continuous = true; // Keep listening continuously
        wakeWordRecognition.interimResults = true; // Process interim results for faster detection
        wakeWordRecognition.lang = "en-US";
        wakeWordRecognition.maxAlternatives = 1; // Focus on best result

        wakeWordRecognition.onstart = () => {
          logMsg("üëÇ Wake word detection active");
        };

        wakeWordRecognition.onresult = (event) => {
          // Only process if not already listening
          if (isListening || isProcessing || isSpeaking || activationLock) {
            return;
          }

          const result = event.results[event.results.length - 1];
          const transcript = result[0].transcript.toLowerCase().trim();

          // Process both interim and final results for faster wake word detection
          // but prefer final results
          if (!result.isFinal) {
            // Only process interim if it clearly contains wake word
            if (
              !transcript.includes("robot") &&
              !transcript.includes("hey") &&
              !transcript.includes("hello")
            ) {
              return;
            }
          }

          const confidence = result[0].confidence || 1.0; // Default to 1.0 if browser doesn't provide confidence

          logMsg(
            `üëÇ Heard: "${transcript}" ${
              result.isFinal ? "(final)" : "(interim)"
            } (confidence: ${
              confidence ? (confidence * 100).toFixed(0) : "N/A"
            }%)`
          );

          // Check for wake words - removed confidence threshold since some browsers report 0%
          if (
            transcript.includes("hey robot") ||
            transcript.includes("hello robot") ||
            transcript.includes("hi robot") ||
            transcript.includes("robot") ||
            transcript.includes("hey") ||
            transcript.includes("hello")
          ) {
            activationLock = true; // debounce subsequent triggers
            setTimeout(() => (activationLock = false), 1000); // 1s debounce to prevent double trigger
            logMsg("üé§ Wake word detected with good confidence!");
            activateListening();
          }
        };

        wakeWordRecognition.onerror = (event) => {
          // Silently ignore no-speech and aborted errors (these are normal)
          if (event.error === "no-speech" || event.error === "aborted") {
            return;
          }

          logMsg("‚ö†Ô∏è Wake word error: " + event.error);

          // Only restart on critical errors
          if (
            event.error === "network" ||
            event.error === "audio-capture" ||
            event.error === "not-allowed"
          ) {
            logMsg("üîÑ Restarting wake word detection due to error...");
            setTimeout(() => {
              if (!isListening && !isProcessing) {
                startWakeWordListening();
              }
            }, 1000);
          }
        };

        wakeWordRecognition.onend = () => {
          logMsg("üëÇ Wake word recognition ended unexpectedly");

          // ONLY restart if we're not in active command mode
          // This prevents the constant restart loop you're seeing
          if (!isListening && !isProcessing && !isSpeaking) {
            // Immediate restart without timeout - continuous mode should stay active
            logMsg("üîÑ Restarting wake word to keep always active...");

            // Clear any existing restart timeout
            if (wakeRestartTimeoutId) {
              clearTimeout(wakeRestartTimeoutId);
            }

            // Restart with small delay to prevent rapid fire and instability
            wakeRestartTimeoutId = setTimeout(() => {
              startWakeWordListening();
              wakeRestartTimeoutId = null;
            }, 500); // 500ms delay - balanced for responsiveness and stability
          } else {
            logMsg("‚è∏Ô∏è Not restarting - currently in command mode");
          }
        };
      } // end initWakeWordRecognition

      function startWakeWordListening() {
        if (!wakeWordRecognition) {
          logMsg("‚ùå Wake word recognition not initialized");
          return;
        }

        statusText.textContent = "Listening for wake word...";

        try {
          wakeWordRecognition.start();
          logMsg("üëÇ Wake word listening started");
        } catch (e) {
          if (e.name !== "InvalidStateError") {
            logMsg("‚ùå Failed to start wake word: " + e.message);
          }
        }
      }

      // ===== COMMAND RECOGNITION =====
      function initCommandRecognition() {
        const SpeechRecognition =
          window.SpeechRecognition || window.webkitSpeechRecognition;
        commandRecognition = new SpeechRecognition();
        commandRecognition.continuous = true; // Continuous mode for motor commands
        commandRecognition.interimResults = false; // Only final results
        commandRecognition.lang = "en-US";
        commandRecognition.maxAlternatives = 1; // Best result only

        commandRecognition.onstart = () => {
          logMsg("üé§ Listening for command...");
        };

        commandRecognition.onresult = (event) => {
          // Get the last result (most recent command)
          const lastIndex = event.results.length - 1;
          const result = event.results[lastIndex];

          if (!result.isFinal) {
            return; // Skip interim results
          }

          const transcript = result[0].transcript.trim();
          const confidence = result[0].confidence || 1.0;
          const currentTime = Date.now();

          lastTranscriptText.textContent = `Heard: ${transcript}`;
          lastTranscriptTimestamp = Date.now();

          // Cancel any pending listening acknowledgment when first transcript arrives
          if (listeningAckTimeoutId) {
            clearTimeout(listeningAckTimeoutId);
            listeningAckTimeoutId = null;
          }

          logMsg(
            `üé§ Command heard: "${transcript}" (confidence: ${(
              confidence * 100
            ).toFixed(0)}%)`
          );

          // Ignore empty or very short transcripts (likely noise or echo)
          if (transcript.length < 2) {
            logMsg("‚è≠Ô∏è Ignoring too-short command");
            return;
          }

          // Ignore if currently speaking or processing
          if (isSpeaking || isProcessing) {
            logMsg("üîá Ignoring speech while avatar is speaking/processing...");
            return;
          }

          // Debounce: Ignore if same command within 1 second OR if already processing
          if (commandProcessingLock) {
            logMsg("‚è≥ Still processing previous command, ignoring...");
            return;
          }

          if (
            transcript === lastProcessedCommand &&
            currentTime - lastCommandTime < 300 // shorter debounce to avoid needing repeats
          ) {
            logMsg("üîÑ Duplicate command ignored (too soon)");
            return;
          }

          // Update tracking
          lastProcessedCommand = transcript;
          lastCommandTime = currentTime;

          logMsg("üìù Processing command: " + transcript);

          // Check for exit commands to leave command mode
          const lowerTranscript = transcript.toLowerCase();
          if (
            lowerTranscript.includes("exit") ||
            lowerTranscript.includes("stop listening") ||
            lowerTranscript.includes("go to sleep")
          ) {
            logMsg("üí§ Exiting command mode...");

            // STOP THE MOTORS before exiting!
            if (isBluetoothConnected) {
              sendCommand("S"); // Send stop command
              logMsg("üõë Sending STOP command to car");
            }

            isInCommandMode = false;
            isListening = false;
            commandProcessingLock = false;
            speak(
              "Stopping the car and going to sleep. Say hey robot to wake me up."
            );
            commandRecognition.stop();
            return;
          }

          sendToBot(transcript);
        };

        commandRecognition.onerror = (event) => {
          logMsg("‚ùå Command recognition error: " + event.error);

          // Auto-restart on network errors or audio-capture issues
          if (event.error === "network" || event.error === "audio-capture") {
            logMsg("üîÑ Auto-restarting command recognition...");
            setTimeout(() => {
              if (isInCommandMode && isListening) {
                try {
                  commandRecognition.start();
                } catch (e) {
                  logMsg("‚ö†Ô∏è Could not restart: " + e.message);
                }
              }
            }, 1000);
          }

          // Don't stop on 'no-speech' error in continuous mode
          if (
            event.error !== "no-speech" &&
            event.error !== "aborted" &&
            event.error !== "network"
          ) {
            stopListening();
          }
        };

        commandRecognition.onend = () => {
          logMsg("üé§ Command listening ended");

          // Auto-restart if still in command mode
          if (isInCommandMode && isListening) {
            logMsg("üîÑ Auto-restarting command recognition...");
            setTimeout(() => {
              if (isInCommandMode && isListening) {
                try {
                  commandRecognition.start();
                } catch (e) {
                  logMsg("‚ö†Ô∏è Could not restart: " + e.message);
                }
              }
            }, 500);
          } else if (!isInCommandMode) {
            stopListening();
          }
        };
      }

      // ===== LISTENING CONTROL =====
      function activateListening() {
        // Set flags BEFORE stopping wake word to prevent auto-restart
        isListening = true;
        isInCommandMode = true; // Enter continuous command mode
        lastTranscriptTimestamp = Date.now();

        // Cancel any pending wake-word restarts
        if (wakeRestartTimeoutId) {
          clearTimeout(wakeRestartTimeoutId);
          wakeRestartTimeoutId = null;
        }

        // DON'T stop wake word recognition - keep it running in background!
        // It will automatically ignore results while isListening = true
        // try {
        //   wakeWordRecognition.stop();
        // } catch (e) {
        //   // Already stopped, that's fine
        // }

        statusText.textContent = "Listening...";
        statusRing.className = "status-ring listening";

        // Focus eyes (pupils to center)
        leftPupil.style.transform = "translate(-50%, -50%)";
        rightPupil.style.transform = "translate(-50%, -50%)";

        mouth.className = "mouth";

        // Cancel any pending audible acknowledgments; we avoid speaking here to prevent TTS from blocking STT.
        if (listeningAckTimeoutId) {
          clearTimeout(listeningAckTimeoutId);
          listeningAckTimeoutId = null;
        }

        // If transcripts don't arrive, Web Speech will handle it
        if (listeningAckTimeoutId) {
          clearTimeout(listeningAckTimeoutId);
          listeningAckTimeoutId = null;
        }

        // Stop wake word recognition to avoid conflicts
        try {
          if (wakeWordRecognition) {
            wakeWordRecognition.stop();
            logMsg("‚èπÔ∏è Wake word recognition stopped for command mode");
          }
        } catch (e) {
          if (e.name !== "InvalidStateError") {
            logMsg("‚ö†Ô∏è Could not stop wake word: " + e.message);
          }
        }

        try {
          commandRecognition.start();
          logMsg("üé§ Activated - listening for command (continuous mode)");
        } catch (e) {
          logMsg("‚ùå Failed to start command recognition: " + e.message);
          stopListening();
        }
      }

      function stopListening() {
        isListening = false;
        isInCommandMode = false; // Exit command mode

        if (listeningAckTimeoutId) {
          clearTimeout(listeningAckTimeoutId);
          listeningAckTimeoutId = null;
        }
        if (commandFallbackTimeoutId) {
          clearTimeout(commandFallbackTimeoutId);
          commandFallbackTimeoutId = null;
        }

        // Return to wake word mode after short delay
        setTimeout(() => {
          if (!isProcessing && !isSpeaking) {
            statusText.textContent = "Listening for wake word...";
            statusRing.className = "status-ring";
            startWakeWordListening();
          }
        }, 1500);
      }

      // ===== PROCESS USER SPEECH =====
      async function sendToBot(transcript) {
        isProcessing = true;
        commandProcessingLock = true; // Lock to prevent duplicate processing

        logMsg("üß† Processing: " + transcript);

        statusText.textContent = "Thinking...";
        statusRing.className = "status-ring thinking";
        mouth.className = "mouth thinking";

        // Pupils look up when thinking
        leftPupil.style.transform = "translate(-50%, -80%)";
        rightPupil.style.transform = "translate(-50%, -80%)";

        // Parse for motor commands (always try regardless of API availability)
        const motorCommand = extractMotorCommand(transcript);

        let response = null;

        // If it's a motor command, execute it and give simple response
        if (motorCommand && isBluetoothConnected) {
          await sendCommand(motorCommand);
          // Pupils look down slightly for actions
          leftPupil.style.transform = "translate(-50%, -30%)";
          rightPupil.style.transform = "translate(-50%, -30%)";

          // Give direct response for motor commands - no AI needed
          response = getMotorCommandResponse(motorCommand);

          // For motor commands, clear lock immediately for faster response
          isProcessing = false;
          commandProcessingLock = false;
        } else if (motorCommand && !isBluetoothConnected) {
          // Motor command but not connected
          response =
            "I'm not connected to the robot yet. Please connect first.";
        } else {
          // Not a direct motor command - try local Q&A, then AI intent, then chat

          // 1) Local basic Q&A first (no network)
          response = getBasicAnswer(transcript);

          // 2) Try AI intent understanding (structured JSON) for movement/robot actions
          if (!response && CONFIG.openaiApiKey) {
            const intent = await getAIIntent(transcript);
            if (intent && intent.intent === "move") {
              const execMsg = await executeIntent(intent);
              response = execMsg || "Okay!";
            }
          }

          // 3) If still nothing, use general Gemini chat
          if (!response) {
            if (CONFIG.openaiApiKey) {
              response = await getAIResponse(transcript);
            } else {
              response = politeNoApiFallback();
            }
          }
        }

        // Send to ground station if enabled
        if (CONFIG.groundStationEnabled && CONFIG.groundStationUrl) {
          sendToGroundStation({
            timestamp: new Date().toISOString(),
            userInput: transcript,
            aiResponse: response,
            motorCommand: motorCommand,
            detectedObjects: detectedObjects,
          });
        }

        // Clear locks for non-motor commands (motor commands already cleared above)
        if (!motorCommand || !isBluetoothConnected) {
          isProcessing = false;
          commandProcessingLock = false;
        }

        // KEEP isListening = true for continuous command mode
        isListening = true;

        // STAY IN COMMAND MODE - don't exit automatically
        // User must say "exit" or "stop listening" to leave command mode
        logMsg("‚úÖ Ready for next command (say 'exit' to leave command mode)");

        // Speak response
        speak(response, motorCommand); // Pass motorCommand flag for faster speech
      }

      // ===== BASIC Q&A (offline) =====
      function getBasicAnswer(userInput) {
        if (!userInput) return null;
        const q = userInput.toLowerCase().trim();

        // Greetings
        if (
          /^(hi|hello|hey)\b/.test(q) ||
          q.includes("good morning") ||
          q.includes("good evening") ||
          q.includes("good afternoon")
        ) {
          return "Hello! I‚Äôm your avatar assistant. How can I help you today?";
        }

        // Name / identity
        if (
          q.includes("your name") ||
          q.includes("who are you") ||
          q.includes("what are you")
        ) {
          return "I‚Äôm your friendly avatar assistant. You can call me Robo Buddy.";
        }
        if (
          q.includes(
            "Who is Head of Department of Robotics and AI in REVA UNIVERSITY"
          ) ||
          q.includes("who is Head of Department") ||
          q.includes(
            "what is the name of Head of Department of Robotics and AI"
          )
        ) {
          return "The Head of Department of Robotics and AI in REVA UNIVERSITY is Doctor. Bharathi S.H.";
        }
        if (
          q.includes(
            "Who is the class teacher of 2nd year Robotic and AI in REVA UNIVERSITY"
          ) ||
          q.includes("who is class teacher") ||
          q.includes(
            "what is the name of class teacher of 2nd year Robotic and AI"
          )
        ) {
          return "The class teacher of 2nd year Robotic and AI in REVA UNIVERSITY is professor Krupateja.";
        }
        // Capabilities
        if (
          q.includes("what can you do") ||
          q.includes("help me") ||
          q.includes("how can you help")
        ) {
          return "I can listen, speak, answer questions, and control the robot‚Äîlike moving forward, backward, left, right, or stop. What would you like to do?";
        }

        // Age / origin
        if (q.includes("how old are you") || q.includes("your age")) {
          return "I don‚Äôt really have an age, but I‚Äôm always learning new tricks.";
        }
        if (
          q.includes("where are you from") ||
          q.includes("where do you live")
        ) {
          return "I live right here on your device, and I‚Äôm happy to be at your service.";
        }

        // Creator
        if (
          q.includes("who made you") ||
          q.includes("who created you") ||
          q.includes("who built you")
        ) {
          return "I was assembled by Ganesh chandru,Jyothsna,sinchana shetty and Priya. Nice teamwork!";
        }

        // Thanks
        if (q.includes("thank you") || q.includes("thanks")) {
          return "You‚Äôre welcome! If you need anything else, just ask.";
        }

        return null;
      }

      function politeNoApiFallback() {
        return "I can‚Äôt access my AI service right now because my API key seems missing or invalid. I‚Äôll get that sorted. In the meantime, I can still answer basic questions or help with simple robot commands.";
      }

      function getMotorCommandResponse(command) {
        const responses = {
          F: "Moving forward!",
          B: "Moving backward!",
          L: "Turning left!",
          R: "Turning right!",
          S: "Stopping now!",
        };
        return responses[command] || "Command sent!";
      }

      // ===== GEMINI AI INTEGRATION =====
      async function getAIIntent(userInput) {
        try {
          const schema = `You are an intent extractor for a two-wheel robot (PetBot). Extract structured JSON only, no prose. Schema:
{
  "intent": "move" | "none",
  "direction": "forward" | "backward" | "left" | "right" | null,
  "speed": number | null,        // 0-255, default 220 for heavy bot
  "duration_ms": number | null   // 200-5000 recommended; null for continuous
}`;

          const prompt = `${schema}\n\nUser: ${userInput}\nReturn ONLY the JSON.`;

          const resp = await fetch(
            `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=${CONFIG.openaiApiKey}`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({
                contents: [{ parts: [{ text: prompt }] }],
                generationConfig: { temperature: 0.2, maxOutputTokens: 120 },
              }),
            }
          );

          if (!resp.ok) {
            logMsg(`‚ùå Gemini intent error ${resp.status}`);
            return null;
          }
          const data = await resp.json();
          const text = data?.candidates?.[0]?.content?.parts?.[0]?.text || "";
          if (!text) return null;
          // Attempt to parse JSON block from response
          const jsonMatch = text.match(/\{[\s\S]*\}/);
          const jsonText = jsonMatch ? jsonMatch[0] : text;
          try {
            const parsed = JSON.parse(jsonText);
            logMsg("‚úÖ Parsed intent: " + JSON.stringify(parsed));
            return parsed;
          } catch (e) {
            logMsg(
              "‚ö†Ô∏è Intent JSON parse failed: " + e.message + " | text=" + text
            );
            return null;
          }
        } catch (e) {
          logMsg("‚ö†Ô∏è getAIIntent error: " + e.message);
          return null;
        }
      }

      function clamp(n, min, max) {
        return Math.max(min, Math.min(max, n));
      }

      async function executeIntent(intent) {
        if (!intent || intent.intent !== "move") return null;
        if (!isBluetoothConnected) return "I‚Äôm not connected to the robot yet.";

        const dir = intent.direction || "forward";
        const speed = clamp(
          typeof intent.speed === "number" ? intent.speed : 220,
          0,
          255
        );
        const duration =
          typeof intent.duration_ms === "number"
            ? clamp(intent.duration_ms, 100, 8000)
            : null;

        // Map direction to firmware chars
        const dirMap = { forward: "F", backward: "B", left: "L", right: "R" };
        const code = dirMap[dir] || "F";

        try {
          // Set speed first if provided
          if (speed) {
            await sendCommand(`SPEED:${speed}`);
          }
          // Start motion
          await sendCommand(code);
          // Stop after duration
          if (duration) {
            setTimeout(() => {
              sendCommand("S");
            }, duration);
          }
          const human =
            {
              F: "Moving forward",
              B: "Moving backward",
              L: "Turning left",
              R: "Turning right",
            }[code] || "Moving";
          return duration
            ? `${human} for ${(duration / 1000).toFixed(
                1
              )} seconds at speed ${speed}.`
            : `${human} at speed ${speed}.`;
        } catch (e) {
          logMsg("‚ùå executeIntent error: " + e.message);
          return "I couldn't execute that movement.";
        }
      }
      async function getAIResponse(userInput) {
        if (!CONFIG.openaiApiKey) {
          logMsg("‚ö†Ô∏è Gemini API key not set");
          return politeNoApiFallback();
        }

        // Rate limiting check
        const now = Date.now();
        const timeSinceLastCall = now - lastGeminiCallTime;
        if (timeSinceLastCall < GEMINI_MIN_DELAY) {
          const waitTime = GEMINI_MIN_DELAY - timeSinceLastCall;
          logMsg(
            `‚è≥ Rate limit: waiting ${Math.ceil(
              waitTime / 1000
            )}s before calling Gemini...`
          );
          await new Promise((resolve) => setTimeout(resolve, waitTime));
        }

        lastGeminiCallTime = Date.now();

        try {
          logMsg("üîÑ Calling Gemini AI...");

          const response = await fetch(
            `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=${CONFIG.openaiApiKey}`,
            {
              method: "POST",
              headers: {
                "Content-Type": "application/json",
              },
              body: JSON.stringify({
                contents: [
                  {
                    parts: [
                      {
                        text: `You are a helpful robot assistant called Robo Buddy. Keep responses brief (1-2 sentences).\n\nUser asks: ${userInput}`,
                      },
                    ],
                  },
                ],
                generationConfig: {
                  temperature: 0.9,
                  maxOutputTokens: 100,
                },
              }),
            }
          );

          if (!response.ok) {
            const errorText = await response.text();
            logMsg(`‚ùå Gemini API error ${response.status}: ${errorText}`);
            throw new Error(`Gemini API error: ${response.status}`);
          }

          const data = await response.json();

          // Check if response has expected structure with detailed logging
          if (!data.candidates || data.candidates.length === 0) {
            logMsg(
              "‚ùå No candidates in Gemini response: " + JSON.stringify(data)
            );
            throw new Error("Invalid response from Gemini");
          }

          const candidate = data.candidates[0];
          if (
            !candidate.content ||
            !candidate.content.parts ||
            candidate.content.parts.length === 0
          ) {
            logMsg(
              "‚ùå No content/parts in Gemini response: " + JSON.stringify(data)
            );
            throw new Error("Invalid response from Gemini");
          }

          const aiResponse = candidate.content.parts[0].text;

          if (!aiResponse || aiResponse.trim() === "") {
            logMsg("‚ùå Empty text in Gemini response");
            throw new Error("Empty response from Gemini");
          }

          logMsg("‚úÖ Gemini response: " + aiResponse);
          return aiResponse;
        } catch (error) {
          logMsg("‚ùå Gemini error: " + error.message);
          return (
            "I‚Äôm having trouble with the AI service right now. " +
            "I can still help with basic questions and robot commands."
          );
        }
      }

      // ===== MOTOR COMMAND EXTRACTION =====
      function extractMotorCommand(text) {
        const lowerText = text.toLowerCase();
        logMsg("üîç Checking for motor command in: '" + lowerText + "'");

        if (lowerText.includes("forward") || lowerText.includes("ahead")) {
          logMsg("‚úÖ Detected FORWARD command");
          return "F";
        } else if (
          lowerText.includes("backward") ||
          lowerText.includes("back") ||
          lowerText.includes("reverse")
        ) {
          logMsg("‚úÖ Detected BACKWARD command");
          return "B";
        } else if (lowerText.includes("left")) {
          logMsg("‚úÖ Detected LEFT command");
          return "L";
        } else if (lowerText.includes("right")) {
          logMsg("‚úÖ Detected RIGHT command");
          return "R";
        } else if (lowerText.includes("stop") || lowerText.includes("halt")) {
          logMsg("‚úÖ Detected STOP command");
          return "S";
        }

        logMsg("‚ùå No motor command detected");
        return null;
      }

      // ===== BLUETOOTH FUNCTIONS =====
      async function connectBluetooth() {
        try {
          logMsg("üì° Connecting to Bluetooth...");

          // Check if native Android Bluetooth is available
          if (typeof AndroidBluetooth !== "undefined") {
            logMsg("ü§ñ Using native Android Bluetooth");
            AndroidBluetooth.connect();
            // Connection status will be updated by callbacks
            return;
          }

          // Fall back to Web Bluetooth (won't work in WebView but kept for future web support)
          // Check if Web Bluetooth is available
          if (!navigator.bluetooth) {
            const errorMsg = "Web Bluetooth not supported in this browser/mode";
            logMsg("‚ùå " + errorMsg);
            alert(
              errorMsg +
                "\n\nNote: Web Bluetooth requires HTTPS or file:// protocol"
            );
            throw new Error(errorMsg);
          }

          logMsg("üîç Opening device picker...");

          bluetoothDevice = await navigator.bluetooth.requestDevice({
            filters: [
              { namePrefix: "ESP32" },
              { namePrefix: "ESP" },
              { name: "ESP32_Robot_Car" },
            ],
            optionalServices: [UART_SERVICE_UUID],
          });

          logMsg("üîó Connecting to " + bluetoothDevice.name);
          const server = await bluetoothDevice.gatt.connect();

          logMsg("üîç Getting UART service...");
          const service = await server.getPrimaryService(UART_SERVICE_UUID);

          logMsg("üîç Getting TX characteristic...");
          bluetoothCharacteristic = await service.getCharacteristic(
            UART_TX_CHARACTERISTIC_UUID
          );

          isBluetoothConnected = true;
          connectEsp32Btn.textContent = "‚úÖ ESP32 Connected";
          connectEsp32Btn.style.background = "#22c55e";

          logMsg("‚úÖ Bluetooth connected successfully!");
          speak("Connected to ESP32 robot car");

          bluetoothDevice.addEventListener("gattserverdisconnected", () => {
            isBluetoothConnected = false;
            connectEsp32Btn.textContent = "üì∂ Connect ESP32";
            connectEsp32Btn.style.background = "#3b82f6";
            logMsg("‚ùå Bluetooth disconnected");
            speak("Robot car disconnected");
          });
        } catch (error) {
          const errorMsg = "Bluetooth error: " + error.message;
          logMsg("‚ùå " + errorMsg);
          alert(
            "Failed to connect to ESP32\n\n" +
              error.message +
              "\n\nMake sure:\n1. Bluetooth is enabled on phone\n2. ESP32 is powered on\n3. ESP32 is not connected to another device"
          );
          console.error(error);
        }
      }

      // Callbacks from native Android Bluetooth
      window.onBluetoothConnected = function () {
        isBluetoothConnected = true;
        connectEsp32Btn.textContent = "‚úÖ ESP32 Connected";
        connectEsp32Btn.style.background = "#22c55e";
        logMsg("‚úÖ Bluetooth connected successfully!");
        speak("Connected to ESP32 robot car");
      };

      window.onBluetoothDisconnected = function () {
        isBluetoothConnected = false;
        connectEsp32Btn.textContent = "üì∂ Connect ESP32";
        connectEsp32Btn.style.background = "#3b82f6";
        logMsg("‚ùå Bluetooth disconnected");
        speak("Robot car disconnected");
      };

      async function sendCommand(command) {
        if (!isBluetoothConnected) {
          logMsg("‚ö†Ô∏è Not connected to ESP32");
          return;
        }

        try {
          // Use native Android Bluetooth if available
          if (typeof AndroidBluetooth !== "undefined") {
            AndroidBluetooth.send(command + "\n");
            logMsg("üì§ Sent command: " + command);
            return;
          }

          // Fall back to Web Bluetooth
          if (!bluetoothCharacteristic) {
            logMsg("‚ö†Ô∏è Bluetooth characteristic not available");
            return;
          }

          const data = new TextEncoder().encode(command + "\n");
          await bluetoothCharacteristic.writeValue(data);
          logMsg("üì§ Sent command: " + command);
        } catch (error) {
          logMsg("‚ùå Send error: " + error.message);
        }
      }

      // ===== OBJECT DETECTION =====
      async function startObjectDetection() {
        try {
          logMsg("üì∑ Starting camera...");

          // Load COCO-SSD model if not already loaded
          if (!cocoSsdModel) {
            logMsg("üîÑ Loading AI detection model...");
            cocoSsdModel = await cocoSsd.load();
            logMsg("‚úÖ Detection model loaded");
          }

          // Request camera access (FRONT camera for phone)
          cameraStream = await navigator.mediaDevices.getUserMedia({
            video: {
              facingMode: "user", // Use front camera
              width: { ideal: 640 },
              height: { ideal: 480 },
            },
          });

          cameraVideo.srcObject = cameraStream;

          // Wait for video to be ready
          await new Promise((resolve) => {
            cameraVideo.onloadedmetadata = () => {
              cameraVideo.play();
              resolve();
            };
          });

          detectionOverlay.style.display = "block";

          // Run real object detection every 2 seconds
          detectionInterval = setInterval(() => {
            detectObjects();
          }, 2000);

          // Run first detection immediately
          detectObjects();

          logMsg("‚úÖ Object detection started - using AI model");
        } catch (error) {
          logMsg("‚ùå Camera error: " + error.message);
          objectDetectionToggle.checked = false;
        }
      }

      function stopObjectDetection() {
        if (cameraStream) {
          cameraStream.getTracks().forEach((track) => track.stop());
          cameraStream = null;
        }

        if (detectionInterval) {
          clearInterval(detectionInterval);
          detectionInterval = null;
        }

        detectionOverlay.style.display = "none";
        logMsg("üì∑ Object detection stopped");
      }

      function toggleObjectDetection() {
        if (objectDetectionToggle.checked) {
          startObjectDetection();
        } else {
          stopObjectDetection();
        }
      }

      async function detectObjects() {
        if (!cocoSsdModel || !cameraVideo || cameraVideo.readyState !== 4) {
          return; // Model not loaded or video not ready
        }

        try {
          // Detect objects in current video frame
          const predictions = await cocoSsdModel.detect(cameraVideo);

          // Convert to our format and filter by confidence
          detectedObjects = predictions
            .filter((pred) => pred.score > 0.5) // Only show 50%+ confidence
            .map((pred) => ({
              class: pred.class,
              confidence: pred.score.toFixed(2),
              bbox: pred.bbox, // [x, y, width, height]
            }));

          // Log detected objects to console
          if (detectedObjects.length > 0) {
            console.log(
              "üîç Detected Objects:",
              detectedObjects
                .map(
                  (obj) =>
                    `${obj.class} (${(obj.confidence * 100).toFixed(0)}%)`
                )
                .join(", ")
            );

            logMsg(
              `üîç Found: ${detectedObjects.map((obj) => obj.class).join(", ")}`
            );
          }

          updateDetectionDisplay();

          // If object tracking is enabled, track the locked object
          if (CONFIG.trackingEnabled && CONFIG.lockedObject) {
            trackLockedObject();
          }
        } catch (error) {
          console.error("Detection error:", error);
        }
      }

      function updateDetectionDisplay() {
        detectionList.innerHTML = "";
        detectedObjects.forEach((obj) => {
          const item = document.createElement("div");
          item.className = "detection-item";

          // Highlight if this is the locked object
          if (CONFIG.lockedObject && obj.class === CONFIG.lockedObject.class) {
            item.style.backgroundColor = "#ff6b6b";
            item.style.color = "white";
            item.style.fontWeight = "bold";
          }

          item.textContent = `${obj.class} (${(obj.confidence * 100).toFixed(
            0
          )}%)`;

          // Click to lock/unlock object
          item.style.cursor = "pointer";
          item.onclick = () => lockObject(obj);

          detectionList.appendChild(item);
        });
      }

      // Lock an object for tracking
      function lockObject(obj) {
        if (CONFIG.lockedObject && CONFIG.lockedObject.class === obj.class) {
          // Unlock
          CONFIG.lockedObject = null;
          CONFIG.trackingEnabled = false;
          logMsg(`üîì Unlocked ${obj.class}`);
          sendCommand("S"); // Stop robot

          // Broadcast unlock to remote phones
          if (websocket && websocket.readyState === WebSocket.OPEN) {
            websocket.send(
              JSON.stringify({
                type: "unlock",
              })
            );
          }
        } else {
          // Lock
          CONFIG.lockedObject = obj;
          CONFIG.trackingEnabled = true;
          logMsg(`üîí Locked onto ${obj.class} - Robot will follow`);

          // Broadcast lock to remote phones
          if (websocket && websocket.readyState === WebSocket.OPEN) {
            websocket.send(
              JSON.stringify({
                type: "lock",
                object: obj,
              })
            );
          }
        }
        updateDetectionDisplay();
      }

      // Track the locked object and move robot
      function trackLockedObject() {
        const now = Date.now();
        if (now - lastTrackingCommand < TRACKING_COMMAND_DELAY) {
          return; // Don't spam commands
        }

        // Find the locked object in current detections
        const target = detectedObjects.find(
          (obj) => obj.class === CONFIG.lockedObject.class
        );

        if (!target) {
          logMsg(`‚ö†Ô∏è Lost sight of ${CONFIG.lockedObject.class}`);
          sendCommand("S"); // Stop if object not visible
          return;
        }

        // Calculate object center position
        const [x, y, width, height] = target.bbox;
        const centerX = x + width / 2;
        const centerY = y + height / 2;

        // Video dimensions
        const videoWidth = cameraVideo.videoWidth;
        const videoHeight = cameraVideo.videoHeight;

        // Calculate relative position (0 to 1)
        const relativeX = centerX / videoWidth;
        const relativeY = centerY / videoHeight;

        // Define zones for movement
        const leftZone = 0.35;
        const rightZone = 0.65;
        const topZone = 0.35;
        const bottomZone = 0.65;

        let command = null;

        // Horizontal positioning
        if (relativeX < leftZone) {
          command = "L"; // Turn left
          logMsg(`‚Ü©Ô∏è Target left - turning left`);
        } else if (relativeX > rightZone) {
          command = "R"; // Turn right
          logMsg(`‚Ü™Ô∏è Target right - turning right`);
        }
        // Vertical positioning (distance estimation)
        else if (relativeY > bottomZone) {
          command = "B"; // Move backward (object too close)
          logMsg(`‚¨áÔ∏è Target too close - backing up`);
        } else if (relativeY < topZone) {
          command = "F"; // Move forward (object far)
          logMsg(`‚¨ÜÔ∏è Target far - moving forward`);
        } else {
          // Object is centered - stop
          command = "S";
          logMsg(`‚úÖ Target centered - holding position`);
        }

        if (command) {
          sendCommand(command);
          lastTrackingCommand = now;
        }
      }

      // ===== GROUND STATION COMMUNICATION =====
      function toggleGroundStation() {
        if (groundStationToggle.checked) {
          logMsg("üõ∞Ô∏è Ground station enabled");
        } else {
          logMsg("üõ∞Ô∏è Ground station disabled");
        }
      }

      async function sendToGroundStation(data) {
        if (!CONFIG.groundStationUrl) {
          logMsg("‚ö†Ô∏è Ground station URL not set");
          return;
        }

        try {
          logMsg("üì° Sending to ground station...");

          const response = await fetch(CONFIG.groundStationUrl, {
            method: "POST",
            headers: {
              "Content-Type": "application/json",
            },
            body: JSON.stringify(data),
          });

          if (response.ok) {
            logMsg("‚úÖ Data sent to ground station");
          } else {
            logMsg("‚ùå Ground station error: " + response.status);
          }
        } catch (error) {
          logMsg("‚ùå Ground station error: " + error.message);
        }
      }

      // ===== SPEAK RESPONSE =====
      function speak(text, isMotorCommand = false) {
        isSpeaking = true;

        logMsg("üó£Ô∏è Speaking: " + text);

        statusText.textContent = "Speaking...";
        statusRing.className = "status-ring speaking";
        mouth.className = "mouth speaking";

        // Center pupils when speaking
        leftPupil.style.transform = "translate(-50%, -50%)";
        rightPupil.style.transform = "translate(-50%, -50%)";

        // Try Android native TTS first (more reliable on WebView)
        if (typeof AndroidTTS !== "undefined" && AndroidTTS.isAvailable()) {
          logMsg("üîä Using Android native TTS");
          try {
            AndroidTTS.speak(text);
            logMsg("‚úÖ Android TTS triggered");
            // Estimate speech duration for finish callback
            const duration = Math.max(2000, text.length * 50);
            setTimeout(() => {
              finishSpeaking(isMotorCommand);
            }, duration);
            return;
          } catch (e) {
            logMsg("‚ùå Android TTS failed: " + e.message);
          }
        }

        // Fallback to Web Speech Synthesis
        if (window.speechSynthesis && synthesis) {
          logMsg("üîä Using Web Speech Synthesis");
          // Cancel any previous speech
          try {
            synthesis.cancel();
          } catch (e) {
            logMsg("‚ö†Ô∏è Cancel failed: " + e.message);
          }

          // Ensure audio is unlocked before speaking
          unlockAudio();

          // Wait a bit if voices aren't loaded yet
          const trySpeak = () => {
            const voices = window.speechSynthesis.getVoices();
            logMsg(`üé§ Available voices: ${voices.length}`);

            const utterance = new SpeechSynthesisUtterance(text);

            // Try to use English voice explicitly
            const englishVoice = voices.find((v) => v.lang.startsWith("en"));
            if (englishVoice) {
              utterance.voice = englishVoice;
              logMsg(`üé§ Using voice: ${englishVoice.name}`);
            }

            // Faster speech for motor commands to reduce lag
            utterance.rate = isMotorCommand ? 1.3 : 1.0;
            utterance.pitch = 1.0;
            utterance.volume = 1.0; // Maximum volume
            utterance.lang = "en-US";

            utterance.onstart = () => {
              logMsg("üîä Speech started");
            };

            utterance.onend = () => {
              logMsg("‚úÖ Speaking complete");
              finishSpeaking(isMotorCommand);
            };

            utterance.onerror = (event) => {
              logMsg("‚ùå Speech error: " + event.error);
              // Common errors: 'not-allowed', 'canceled', 'interrupted'
              if (event.error === "not-allowed") {
                logMsg("‚ö†Ô∏è Speech not allowed - tap screen to enable audio!");
              }
              finishSpeaking(isMotorCommand);
            };

            // Speak immediately - no delay needed now
            try {
              window.speechSynthesis.speak(utterance);
              logMsg("üîä Speech synthesis triggered");
            } catch (e) {
              logMsg("‚ùå Speech synthesis exception: " + e.message);
              finishSpeaking(isMotorCommand);
            }
          };

          // If voices not loaded, wait briefly
          if (
            window.speechSynthesis.getVoices().length === 0 &&
            !voicesLoaded
          ) {
            logMsg("‚è≥ Waiting for voices...");
            setTimeout(trySpeak, 100);
          } else {
            trySpeak();
          }
        } else {
          logMsg(
            "‚ùå No TTS available - AndroidTTS: " +
              (typeof AndroidTTS !== "undefined") +
              ", window.speechSynthesis: " +
              !!window.speechSynthesis +
              ", synthesis: " +
              !!synthesis
          );
          // Fallback - just finish speaking without audio
          setTimeout(
            () => {
              finishSpeaking(isMotorCommand);
            },
            isMotorCommand ? 1000 : 3000
          );
        }
      }

      function finishSpeaking(isMotorCommand = false) {
        isSpeaking = false;
        mouth.className = "mouth happy";

        // Quick return to listening mode - very short delays for motor commands
        const initialDelay = isMotorCommand ? 100 : 500; // Even faster for motor commands
        const cooldownDelay = isMotorCommand ? 100 : 500; // Minimal cooldown

        // Wait a moment, then check if we should stay in command mode
        setTimeout(() => {
          mouth.className = "mouth";

          if (isInCommandMode) {
            // Stay in command mode - just update UI (recognition is already running continuously)
            statusText.textContent = "Listening...";
            statusRing.className = "status-ring listening";
            isListening = true;

            // Add a small cooldown before accepting next command
            setTimeout(() => {
              lastProcessedCommand = ""; // Clear last command to allow new ones
              logMsg("üé§ Ready for next command (continuous mode)...");
            }, cooldownDelay);
          } else {
            // Return to wake word mode quickly
            statusText.textContent = "Listening for wake word...";
            statusRing.className = "status-ring";
            startWakeWordListening();
          }
        }, initialDelay);
      }

      // ===== HELPER FUNCTIONS =====
      function getActionName(action) {
        const actions = {
          F: "moving forward",
          B: "moving backward",
          L: "turning left",
          R: "turning right",
          S: "stopping",
        };
        return actions[action] || "performing action";
      }

      // ===== EYE ANIMATIONS =====
      function animateEyes() {
        // Don't move eyes if actively doing something
        if (isListening || isProcessing || isSpeaking) {
          return;
        }

        // Random pupil movement for natural look
        const moveX = (Math.random() - 0.5) * 24; // -12 to +12
        const moveY = (Math.random() - 0.5) * 16; // -8 to +8

        leftPupil.style.transform = `translate(calc(-50% + ${moveX}px), calc(-50% + ${moveY}px))`;
        rightPupil.style.transform = `translate(calc(-50% + ${moveX}px), calc(-50% + ${moveY}px))`;
      }

      // ===== UTILITIES =====

      function toggleLog() {
        logConsole.classList.toggle("visible");
        toggleLogBtn.textContent = logConsole.classList.contains("visible")
          ? "Hide Log"
          : "Show Log";
      }

      function logMsg(message) {
        const timestamp = new Date().toLocaleTimeString();
        const logEntry = document.createElement("div");
        logEntry.className = "log-entry";
        logEntry.textContent = `[${timestamp}] ${message}`;
        logConsole.appendChild(logEntry);

        logConsole.scrollTop = logConsole.scrollHeight;

        if (logConsole.children.length > 100) {
          logConsole.removeChild(logConsole.firstChild);
        }

        console.log(message);
      }

      // ===== START APPLICATION =====
      window.addEventListener("DOMContentLoaded", init);
    </script>
  </body>
</html>
